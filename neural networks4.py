# -*- coding: utf-8 -*-
"""Ащимов Арсеній БС-14 КП№5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wmAJ6Z615hhVFvqZaiOj_diCWiqf0zdP
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l1, l2
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.datasets import fetch_california_housing
import matplotlib.pyplot as plt
from keras.optimizers import Adam

# 1. Вибір та підготовка даних
data = fetch_california_housing()

# Попередня обробка даних
X, y = data.data, data.target
# Розділення на тренувальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Нормалізація даних
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2. Ініціалізація моделі
def create_model():
    model = Sequential()
    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))
    return model

def create_reg_model(regularizer):
    model = Sequential()
    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer, input_dim=X_train.shape[1]))
    model.add(Dense(32, activation='relu', kernel_regularizer=regularizer))
    model.add(Dense(1))
    return model

def create_dropout_model(rate=0.5):
    model = Sequential()
    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
    model.add(Dropout(rate))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))
    return model

def create_batchnorm_model():
    model = Sequential()
    model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
    model.add(BatchNormalization())
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))
    return model

# 5. Оцінка та порівняння моделей
models = {
    'Basic': create_model(),
    'L1 Regularized': create_reg_model(l1(0.01)),
    'L2 Regularized': create_reg_model(l2(0.01)),
    'Dropout': create_dropout_model(),
    'BatchNorm': create_batchnorm_model()
}

history = {}
for name, model in models.items():
    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')
    history[name] = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32, verbose=0)

# Оцінка моделей
results = {}
for name, model in models.items():
    train_predictions = model.predict(X_train)
    test_predictions = model.predict(X_test)

    train_mae = mean_absolute_error(y_train, train_predictions)
    test_mae = mean_absolute_error(y_test, test_predictions)

    train_mse = mean_squared_error(y_train, train_predictions)
    test_mse = mean_squared_error(y_test, test_predictions)

    results[name] = {'train_mae': train_mae, 'test_mae': test_mae, 'train_mse': train_mse, 'test_mse': test_mse}

# Візуалізація кривих навчання та втрат
for name, hist in history.items():
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(hist.history['loss'], label='Train Loss')
    plt.plot(hist.history['val_loss'], label='Validation Loss')
    plt.title(f'{name} - Training & Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.tight_layout()
    plt.show()

# 6. Аналіз результатів
for name, result in results.items():
    print(f"{name} Model:")
    for metric, value in result.items():
        print(f"{metric}: {value:.4f}")
    print("\n")